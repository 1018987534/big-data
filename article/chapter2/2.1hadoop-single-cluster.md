# 2.1 Hadoop伪分布式安装部署

>开源地址 https://github.com/wangxiaoleiAI/big-data
>
[卜算子·大数据 目录](./../../README.md)
>
开源“卜算子·大数据”系列文章、源码，面向大数据（分布式计算）的编程、应用、架构——每周更新！Linux、Java、Hadoop、Spark、Sqoop、hive、pig、hbase、zookeeper、Oozie、flink...etc


本节介绍如何在Linux系统中快速安装Hadoop伪分布式部署（[1.1 Virtualbox虚拟机快速入门](./../chapter1/1.1virtualbox-quick-start.md) 在vitualbox中安装Ubuntu18.04）

## 2.1.1 前期准备
### 1.服务器准备
- 可以选择本地(Linux　debian/Ubuntu)安装
- 也可以虚拟安装，虚拟机也可以增加第二块网卡host-only（设置enp0s8　为静态ip,192.168.56.101，使得本地可以连接虚拟机服务器。
- 服务器准备查看[1.2 linux使用技巧快速入门.md](./../1.2.linux使用技巧快速入门.md) [1.3 virtualbox高级应用构建本地大数据集群服务器.md](./../1.3.virtualbox高级应用构建本地大数据集群服务器.md)
### 2. 下载最新版本Hadoop3.1.0

下载地址
https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.0/hadoop-3.1.0.tar.gz

也可以通过wget命令行下载
```sh
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.0/hadoop-3.1.0.tar.gz
```
### 3. 安装Java

- 准备文件

```sh
# 创建jdk文件夹
sudo mkdir -p /opt/java

# 进入Downloads文件夹
cd ~/Downloads

# 通过wget下载
wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u172-b11/a58eab1ec242421181065cdc37240b08/jdk-8u172-linux-x64.tar.gz

# 解压
tar -zxf jdk-8u172-linux-x64.tar.gz

# 将jdk文件夹移动到/opt/java/
sudo mv jdk1.8.0_172/ /opt/java/jdk1.8.0_172/
```

- 配置Java变量文件[源码](./../../code/chapter2/2.1hadoop-single-cluster)

1.通过vim创建jdk-1.8.sh文件
```sh
sudo vim /etc/profile.d/jdk-1.8.sh
```
2.添加如下内容
```sh
#!/bin/sh
# Author:wangxiaolei 王小雷
# Github: https://github.com/wangxiaoleiai
# Date: 2018.06

export JAVA_HOME=/opt/java/jdk1.8.0_172
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
```
3.让Java变量生效
```sh
source /etc/profile
```
4.查看已配置完成的Java
```sh
java -version
```

![](./../image/chapter2/2.1/java-version1.png)


### 4. 安装ssh pdsh
```sh
sudo apt-get install ssh
sudo apt-get install pdsh
```
### 5. 免密码登录

```sh
# 创建ssh密匙，执行如下命令后回车到底
ssh-keygen -t rsa
# 将产生的公共密匙追加到authorized_keys
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
# 尝试免密码登录（初次登录会询问然后需要输入yes，二次登录可以直接登录）配置成功
ssh localhost
```

## 2.1.2 配置Hadoop环境变量

```sh
sudo vim /etc/profile.d/hadoop-3.1.0.sh
```
增加如下内容

```sh
#!/bin/sh
# Author:wangxiaolei 王小雷
# Github: https://github.com/wangxiaoleiai

export HADOOP_HOME="/opt/hadoop/hadoop-3.1.0"
export PATH="$HADOOP_HOME/bin:$PATH"
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
```
使变量生效
```sh
source /etc/profile
```

## 2.1.3 伪分布式——在配置文件中添加如下内容（[源码](./../../code/chapter2/2.1hadoop-single-cluster)）

1. etc/hadoop/hadoop-env.sh

```sh
export JAVA_HOME=/opt/java/jdk1.8.0_172
```

2. etc/hadoop/core-site.xml

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>

```

3. etc/hadoop/hdfs-site.xml

```xml
<configuration>

    <property>
      <name>dfs.namenode.name.dir</name>
      <value>/var/lib/hadoop/hdfs/name/</value>
    </property>
    <property>
      <name>dfs.datanode.data.dir</name>
      <value>/var/lib/hadoop/hdfs/data/</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>

</configuration>
```

## 2.1.4 伪分布式——执行
1. 创建HDFS系统文件，并且改权限为hadoop用户，设置rcmd_default入口。

```sh
sudo mkdir /var/lib/hadoop
sudo chown busuanzi:busuanzi /var/lib/hadoop/
```

![](./../image/chapter2/2.1/chown-hadoop1.png)

```bash
# 新建rcmd_default文件
# 设置rcmd_default入口，避免出现 master: rcmd: socket: Permission denied
sudo sh -c "echo "ssh" > /etc/pdsh/rcmd_default"
```

２. 格式化(注意格式化只需要执行一次即可)

```sh
bin/hdfs namenode -format
```

![](./../image/chapter2/2.1/format2.png)



3. 开启NameNode和DataNode

```sh
sbin/start-dfs.sh
```

4. jps查看启动成功

```sh
jps
```

![](./../image/chapter2/2.1/start-dfs1.png)

5. 浏览器访问namenode  http://localhost:9870/

**注意，自Hadoop3.0之后，http://localhost:5007/ 变成http://localhost:9870/** [官方解释](https://issues.apache.org/jira/browse/HDFS-9427)


![](./../image/chapter2/2.1/9870.png)

6. 拓展——Hadoop哪些端口在3.0之后被改掉

```
Namenode ports
----------------
50070 --> 9070
50470 --> 9470

Datanode ports
---------------
50010 --> 9010
50020 --> 9020
50075 --> 9075
50475 --> 9475

Secondary NN ports
---------------
50090 --> 9090
50091 --> 9091
```

## 2.1.4 YARN伪分布式文件配置 [源码](./../../code/chapter2/2.1hadoop-single-cluster)

1. etc/hadoop/mapred-site.xml:

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
```

2. etc/hadoop/yarn-site.xml:

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```

## 2.1.5 启动YARN

1. 启动YARN
```sh
sbin/start-yarn.sh
```

2. 使用jps查看启动情况
```sh
jps
```

![](./../image/chapter2/2.1/start-yarn1.png)

3. 浏览器访问ResourceManager  http://localhost:8088/

![](./../image/chapter2/2.1/8088.png)

至此，伪分布式部署完成。

## 2.1.6 开启历史查看服务

```sh
bin/mapred --daemon start historyserver
```
![](./../image/chapter2/2.1/start-his.png)

访问　 http://localhost:19888/
![](./../image/chapter2/2.1/19888.png)

## 2.1.6 停止伪分布式后台进程

1. 停止YARN

```sh
sbin/stop-yarn.sh
```

2. 停止Namenode和Datanode

```sh
sbin/stop-dfs.sh
```

3. 停止历史服务

```sh
bin/mapred --daemon stop historyserver
```

## 2.1.7 如果要清除Hadoop，彻底删除Hadoop相关文件与配置

```sh
rm -rf /opt/hadoop/hadoop-3.1.0/logs
rm -rf /var/lib/hadoop*
```


> 开源地址：https://github.com/wangxiaoleiAI/big-data

大数据完整知识体系原创分享，长按关注微信公众号【从入门到精通】，进群交流、获取一手更新资讯。

![](./../../article/image/user/share/qrcode_for_gh_6932763778ef_344.jpg)
